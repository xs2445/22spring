{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24dc8b00",
   "metadata": {},
   "source": [
    "# Lab - YOLOv4-Tiny - Darknet Setup\n",
    "## E6692 Spring 2022\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d06ee84",
   "metadata": {},
   "source": [
    "In this Lab you will train YOLOv4-Tiny using the Darknet framework. Darknet is an open source neural network framework written in C and CUDA, which means it's efficient and outperforms TensorFlow/PyTorch in terms of training times for similar networks. However, it may feel slightly less intuitive to a Python programmer. This notebook will guide you through the setup process. You should execute these cells on the GCP instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddb7f4d",
   "metadata": {},
   "source": [
    "The first step in setting up Darknet is to specify the build configuration. This is done by editing the Makefile. We need to specify `GPU=1`, `CUDNN=1`, `CUDNN_HALF=1`, and `OPENCV=1` to use the GPU for parallel operations, the cuDNN GPU acceleration libraries, half precision operations, and OpenCV for loading images. We also need to specify the GPU architecture by uncommenting the `ARCH` variable that corresponds to your instance's GPU. \n",
    "\n",
    "**TODO:** Open **darknet/Makefile** and make the changes specified above. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439ec33f",
   "metadata": {},
   "source": [
    "## Install OpenCV\n",
    "\n",
    "We need to install the C distribution of OpenCV (Open Source Computer Vision Library) for image processing. \n",
    "\n",
    "**TODO:** Open a terminal and enter the command `sudo apt-get install libopencv-dev` to install OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b924d173",
   "metadata": {},
   "source": [
    "## Build Darknet\n",
    "\n",
    "To compile the darknet project code, we simply execute the command `make` in the darknet directory. The Makefile specifies the configuration details of the Darknet setup. All dependancies are all located within the directory. \n",
    "\n",
    "**TODO**: In the terminal, navigate to the `darknet` directory and enter `make`. You will see the compilation output and several warnings, which is OK. The darknet code should execute without errors. \n",
    "\n",
    "After you've compiled the Darknet code and completed the discussion questions below, you can start on the training notebook **darknet/DarknetTraining.ipynb**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987b0277",
   "metadata": {},
   "source": [
    "## Discussion Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a008c915",
   "metadata": {},
   "source": [
    "In the previous lab you implemented the forward pass of a basic CNN in CUDA. The Darknet framework works in the same way - CNN layers are defined in CUDA such that they can be calculated on GPUs - but it also has a lot more functionality than what you implemented. For instance, there are libraries of different activation functions, layer types, and loss functions all implemented in CUDA and C that can be combined to generate complex model architectures. To get a better sense of how Darknet is combining CPU and GPU functionality to complete the computations necessary for Deep Learning, take a look at **darknet/src**. This directory contains the Darknet source code for individual model operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8cde2c",
   "metadata": {},
   "source": [
    "Open **darknet/src/activation_kernels.cu**, **darknet/src/activation_kernels.c**, and **darknet/src/activation_kernels.h** and look through the functions in these files. Describe the purpose of these functions and their designation to **.cu**, **.c**, or **.h**. How do these C and CUDA functions work to produce activation functions? How do they calculate the gradients of these activation functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eb8c00",
   "metadata": {},
   "source": [
    "**TODO:** Your answer here.\n",
    "\n",
    "Functions are defined in the .h file and implemented in the .c file. GPU implementations are in .cu file and those implementations are used in functions in .c file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcb1121",
   "metadata": {},
   "source": [
    "Open **darknet/src/dark_cuda.c**. Describe the purpose of the following functions: **cuda_free()**, **cuda_free_host()**, **cuda_push_array()**, **cuda_pull_array()**, **cuda_pull_array_async()**, and **get_number_of_blocks()**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111d0540",
   "metadata": {},
   "source": [
    "**TODO:** Your answer here.\n",
    "\n",
    "1. cuda_free()\n",
    "\n",
    "Free the memory of GPU amd check the status of it.\n",
    "\n",
    "2. cuda_free_host()\n",
    "\n",
    "Frees page-locked memory.\n",
    "\n",
    "3. cuda_push_array()\n",
    "\n",
    "Copy the array from host to device.\n",
    "\n",
    "4. cuda_pull_array()\n",
    "\n",
    "Copy the array from device to host.\n",
    "\n",
    "5. cuda_pull_array_async()\n",
    "\n",
    "Direction of the transfer is inferred from the pointer values. Requires unified virtual addressing. \n",
    "\n",
    "6. get_number_of_blocks()\n",
    "\n",
    "The number of blocks on devices required for the array.\n",
    "\n",
    "reference:\n",
    "\n",
    "https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9914b6",
   "metadata": {},
   "source": [
    "What is the purpose of the \"CHECK_CUDA(status);\" lines in these functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49bc47d",
   "metadata": {},
   "source": [
    "**TODO:** Your answer here.\n",
    "\n",
    "To check if the operation is successful. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d95fe1",
   "metadata": {},
   "source": [
    "Compare your implementation of MaxPool2D, and conv2D in the previous lab to the corresponding Darknet implementations: **src/darknet/convolutional_kernels.forward_convolutional_layer_gpu()** and **src/darknet/maxpool_layer_kernels.forward_maxpool_layer_kernel()**. Briefly explain how the backward pass functions work (backward_convolutional_layer_gpu() and backward_maxpool_layer_kernel())."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095a1357",
   "metadata": {},
   "source": [
    "**TODO:** Your answer here.\n",
    "\n",
    "1. Convolutional_layer_gpu()\n",
    "\n",
    "They used a technique called im2col and also General Matrix Multiply (GEMM) to simplify and accelerate the convolutional operation. Also, shared memory were used in the function to reduce the number of fetch data from global memory.\n",
    "\n",
    "2. forward_maxpool_layer_kernel()\n",
    "\n",
    "This function is not too much different from my implementation. This is probably because maxpooling is a simple operation that data fetching can't be avoided.\n",
    "\n",
    "3. backward_convolutional_layer_gpu()\n",
    "\n",
    "Backward probagation of convolutional layer is also a convolutional opertion, so it is similar to the forward implementation.\n",
    "\n",
    "4. backward_maxpool_layer_kernel()\n",
    "\n",
    "Backward of maxpooling is also similar to the forward implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eab8b84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
