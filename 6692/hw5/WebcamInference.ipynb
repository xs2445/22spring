{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf4f49d3",
   "metadata": {},
   "source": [
    "# Lab - YOLOv4-Tiny - Pretrained YOLOv4-Tiny Webcam Inference\n",
    "## E6692 Spring 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05257fc3",
   "metadata": {},
   "source": [
    "In this part we do inference with YOLOv4-Tiny through the webcam. You will load the pretrained YOLOv4-Tiny [Darknet](https://pjreddie.com/darknet/) weights into a PyTorch implementation of the model. The weights we are using were trained on the **COCO (Common Objects in COntext)** computer vision dataset comprised of 80 classes of common objects. Read more about the dataset [here](https://cocodataset.org/#home). Complete this notebook on the Jetson Nano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c17a0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard libraries\n",
    "import torch\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "\n",
    "# import custom libraries\n",
    "from darknet_utils.darknet_to_pytorch import load_darknet_as_pytorch\n",
    "from darknet_utils.utils import plot_boxes_cv2, post_processing, nms_cpu\n",
    "from darknet_utils.torch_utils import detect\n",
    "from darknet_utils.inference import image_inference, webcam_inference, get_class_names\n",
    "from darknet_utils.download_images import download_n_images\n",
    "\n",
    "# define weights and configuration file paths\n",
    "cfg_path = './cfg/yolov4-COCO-pretrained.cfg'\n",
    "weights_path = './weights/yolov4-tiny.weights'\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f9756",
   "metadata": {},
   "source": [
    "The PyTorch YOLOv4-Tiny model is defined in **darknet_utils/darknet_model.py**. Note that the model contains a \"load_weights\" function. The model is also defined by parsing the configuration file. This allows for easy reconfiguration and versioning of the model. Load the pretrained YOLOv4-Tiny weights into the PyTorch implementation with the function **load_darknet_as_pytorch()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb62caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use load_darknet_as_pytorch() to load the pretrained YOLOv4-Tiny PyTorch model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9e6741",
   "metadata": {},
   "source": [
    "Next you will download images for sample inference. We will use **download_n_images()** as we did in previous labs. Note that the model was trained on 80 classes of objects. You may want to adjust your query to reflect these classes. See **ms_coco_classnames.txt** for the full list of classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bff188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Download at least 3 images with download_n_images() to use for inference.\n",
    "\n",
    "query = 'sports'\n",
    "n = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee84197",
   "metadata": {},
   "source": [
    "In **darknet_utils.inference**, implement the function **get_class_names()**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dafc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use get_class_names() to load the COCO classes as a dictionary of class indices and class names.\n",
    "\n",
    "class_names = {}\n",
    "\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcaf396",
   "metadata": {},
   "source": [
    "In **darknet_utils.inference** complete the function **image_inference()**. Then use it to perform inference with the pretrained YOLOv4-Tiny on at least 3 of the images you downloaded. You will need to define a confidence threshold and an [NMS threshold](https://learnopencv.com/non-maximum-suppression-theory-and-implementation-in-pytorch/#:~:text=Deep%20Learning%20Face%20Detection%20Object,out%20of%20many%20overlapping%20entities.) for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8030784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: complete image_inference() and use it to perform inference on the images you downloaded.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d26b04",
   "metadata": {},
   "source": [
    "How do the detections change as you adjust the confidence and NMS thresholds?\n",
    "\n",
    "**TODO:** Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b40a3e",
   "metadata": {},
   "source": [
    "Use the function **webcam_inference()** to do pretrained inference through the webcam of the Jetson Nano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam_inference(pretrained_yolo_tiny, class_names=class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011fb946",
   "metadata": {},
   "source": [
    "How does the YOLOv4-Tiny inference compare to the live inferences you have performed in previous labs? What happens if you increase the resolution of the live inference? Experiment with detecting and describe edge cases where the detection accuracy is poor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4020d0",
   "metadata": {},
   "source": [
    "**TODO:** Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70552ad3",
   "metadata": {},
   "source": [
    "**TODO:** Insert a screenshot of your webcam pretrained inference with some good detections of COCO objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d68c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
