{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28859b29",
   "metadata": {},
   "source": [
    "# Lab - Data Collection - Training\n",
    "## E6692 Spring 2022\n",
    "\n",
    "VERSION WITH SOLUTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c925586",
   "metadata": {},
   "source": [
    "In part 2 of this lab we will be collecting and labeling data for a regression task with the Logitech webcam, training regression models, and performing live inference through the webcam with the trained models. We will define and train a custom CNN regression model that inherits from the PyTorch **nn.Module**, as well as fine tuning a pretrained ResNet model. The process for labeling the regression data is slightly different from part 1. See **Label Regression Data** and the docstring of **regression_labeling.py** for details.\n",
    "\n",
    "To use the webcam in this lab you need to specify it when mounting the docker by adding the tag `--device /dev/video0`. Additionally, you should include a data volume for storing images. We recommended that you have a `data` folder in the root directory of your Jetson Nano, and subsequent lab folders within this data folder. For example, the data for this lab would be stored in `~/data/Lab-DataCollectionAndTraining`. Then you can include the external data directory when mounting the docker with `--volume ~/data/Lab-DataCollectionAndTraining:/docker/path/to/lab`.\n",
    "\n",
    "\n",
    "## Part 2.1: Data Collection for Regression\n",
    "\n",
    "In this part we collect and label image data for regression using the Jetson Nano webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58f1dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.data_collection import DATA_SHAPE\n",
    "from utils.datasets import RegressionDataset, get_label_dict\n",
    "from utils.data_collection import collect_regression_data\n",
    "from utils.models import CustomRegression\n",
    "from utils.training import train_regression\n",
    "from utils.live_inference import live_regression\n",
    "\n",
    "# define paths\n",
    "data_path = './data/regression'\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "\n",
    "labeled_data_path = os.path.join(data_path, 'labeled')\n",
    "if not os.path.exists(labeled_data_path):\n",
    "    os.makedirs(labeled_data_path)\n",
    "    \n",
    "unlabeled_data_path = os.path.join(data_path, 'unlabeled')\n",
    "if not os.path.exists(unlabeled_data_path):\n",
    "    os.makedirs(unlabeled_data_path)\n",
    "\n",
    "train_path = os.path.join(labeled_data_path, 'train')\n",
    "if not os.path.exists(train_path):\n",
    "    os.makedirs(train_path)\n",
    "\n",
    "val_path = os.path.join(labeled_data_path, 'val')\n",
    "if not os.path.exists(val_path):\n",
    "    os.makedirs(val_path)\n",
    "    \n",
    "models_path = './models'\n",
    "if not os.path.exists(models_path):\n",
    "    os.makedirs(models_path)\n",
    "\n",
    "labels_path = './regression_labels.txt'\n",
    "\n",
    "device = torch.device('cuda')\n",
    "print(\"GPU name: \", torch.cuda.get_device_name(0))\n",
    "\n",
    "# reload modules every 2 seconds to see changes in notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cf04d3",
   "metadata": {},
   "source": [
    "### Define A Regression Problem\n",
    "\n",
    "Define the regression problem by enumerating the regression classes our model will locate in an image. For example, image regression classes include left/right eye location, nose location, body keypoints, fingertip locations, etc. Define your own regression classes (at least 2), but keep in mind the limitations of collecting data through the webcam (relatively low resolution, confined to objects in the lab, time needed to label) and the capacity of models you are able to run on the Jetson Nano. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300ab507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define the names of regression classes that will be predicted and a name for the regression task. \n",
    "# Replace the following list elements with your regression classes\n",
    "\n",
    "regression_class_names = ['class1', 'class2', 'class3']\n",
    "regression_task_name = 'insert regression task name here'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae9e1c0",
   "metadata": {},
   "source": [
    "### Collect, Preprocess, and Label Data\n",
    "\n",
    "TODO: complete the methods of the class **RegressionDataset** in **utils/datasets.py**. This class inherits from **torch.utils.data.Dataset** to give us compatibility between our custom classification dataset and **torch.utils.data.DataLoader** functionality. \n",
    "\n",
    "#### Data Augmentation\n",
    "\n",
    "To make our custom dataset more robust, we will apply data augmentation transforms.\n",
    "\n",
    "TODO: visit the documentation page for **[torchvision.transforms](https://pytorch.org/vision/main/auto_examples/plot_transforms.html)** to familiarize yourself with data augmentation transforms. Then use **torchvision.transforms.Compose()** to define a data augmentation pipeline.\n",
    "\n",
    "NOTE: data augmentation for regression can run into similar issues as for classification. For example, if you are applying spatial transformations to your images, you would need to apply the same spatial transforms to the regression coordinates. Keep this in mind when choosing augmentations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987e86f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use torchvision.transforms.Compose() to define a data augmentation pipeline\n",
    "\n",
    "transforms = T.Compose([\n",
    "    \n",
    "    # insert data augmentations here\n",
    "    \n",
    "    T.Resize(DATA_SHAPE),\n",
    "    T.ToTensor(), # don't modify Resize(), ToTensor() or Normalize().\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a4660",
   "metadata": {},
   "source": [
    "#### Discuss the differences between data augmentation for classification and regression.\n",
    "\n",
    "TODO: your answer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3908e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define a training set and a validation set with the ClassificationDataset class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30bf5f3",
   "metadata": {},
   "source": [
    "#### Collect Data for Regression\n",
    "\n",
    "Use the function **collect_regression_data()** in **utils/data_collection.py** to collect data for image regression. The labeling process for regression data is slightly different than for classification. Rather than collecting data class by class, we will collect a large set of images from the webcam, then transfer them to your local computer to label them with point and click. Point and click functionality is not readily available in headless mode with the Jetson Nano.\n",
    "\n",
    "Similarly to the classification data collection function, you are welcome to make improvements or modifications to **collect_regression_data()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db14be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use collect_regression_data() to collect training data\n",
    "#       Save the images to the unlabeled data path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8403f805",
   "metadata": {},
   "source": [
    "#### Label Regression Data\n",
    "\n",
    "Now that we have collected data for regression, we need to label it. To do this we will run the python script **regression_labeling.py** locally. Refer to the usage instructions in the doc string for details. \n",
    "\n",
    "TODO: Transfer the unlabeled images to your laptop using scp. Note that this requires dismounting the docker, and that you have saved the images in a volume outside of the docker. From a local terminal use the command `scp -r username@IP:~/Jetson Nano path/to/unlabeled /local/path/to/data` to transfer your unlabeled data from the Jetson Nano. Then run the following cell on your local machine to label the images you collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f1cb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: label your regression data locally with regression_labeling.py\n",
    "# !python3 regression_labeling.py INSTRUCTOR TODO - UNCOMMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a73aa9f",
   "metadata": {},
   "source": [
    "regression_labeling.py will generate a text file that contains the labels for the corresponding images. Once we have the labels file, we can populate the training and validation RegressionDatasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e045dcb4",
   "metadata": {},
   "source": [
    "#### Populate RegressionDataset with Labeled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a531d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the unlabeled images randomly into a training and validation set. \n",
    "\n",
    "train_val_split = 0.8 # define train/val split\n",
    "\n",
    "unlabled_image_names = os.listdir(unlabeled_data_path) # get list of unlabeled image names\n",
    "unlabled_image_names = [i for i in unlabled_image_names if '.jpg' in i] # remove non-images\n",
    "unlabled_length = len(unlabled_image_names) # get number of images\n",
    "\n",
    "split_index = int(train_val_split * unlabled_length) # define split index\n",
    "random.shuffle(unlabled_image_names) # randomly shuffle names\n",
    "\n",
    "unlabled_train_names = unlabled_image_names[:split_index] # split into train and val based on index\n",
    "unlabled_val_names = unlabled_image_names[split_index:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6c9512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use the RegressionDataset.populate_from_files() method to populate \n",
    "#       the regression datasets. Print the length of each to the cell output.\n",
    "\n",
    "# TODO: use RegressionDataset.grid_visualization() to visualize the training \n",
    "#       and validation sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d311a5",
   "metadata": {},
   "source": [
    "#### Discuss the appearance of the train and validation sets. What characteristics are important to observe in a regression dataset before training?\n",
    "\n",
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2901cf8a",
   "metadata": {},
   "source": [
    "## Part 2.2 Custom Image Regression Model Definition\n",
    "\n",
    "Now that we have a dataset, we will define a convolutional neural network model for regression. We will use the [PyTorch functional API](https://pytorch.org/docs/stable/nn.functional.html) to construct a custom CNN regression model. Your model should have convolutional layers for learning features and fully connected layers for keypoint regression. The architecture of your model should be very similar to the classification model, except instead of classification the fully connected layers will be used to regress the keypoints. That means you will need twice as many outputs as regression classes (1 for X, 1 for Y).\n",
    "\n",
    "TODO: Complete the class **CustomRegression** in **utils/models.py**. This class inherits from the [PyTorch nn.Module class](https://pytorch.org/docs/stable/generated/torch.nn.Module.html), which gives it many functionalities including automatic handling of parameter transfer to the GPU. You must redefine the **CustomRegression.forward()** method to define the forward pass of the model with your custom layers. \n",
    "\n",
    "NOTE: Keep in mind the limited memory resources of the Jetson Nano. You may experience issues (kernel dying, notebook freezing) if your model has too many parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e846924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define instance of CustomRegression\n",
    "\n",
    "num_regression_classes = len(regression_class_names) # get the number of classes (output shape)\n",
    "model = CustomRegression(num_regression_classes) # initialize model\n",
    "model.to(device) # transfer model to GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8379941d",
   "metadata": {},
   "source": [
    "## Part 2.3 Custom Classifier Model Training\n",
    "\n",
    "Now we need to train the model on our custom regression dataset. TODO: complete the function **train_regression()** in **utils/training.py**. Use the comments as a guide, and refer to the [PyTorch training loop documentation](https://pytorch.org/tutorials/beginner/introyt/trainingyt.html#:~:text=def%20train_one_epoch(epoch_index%2C%20tb_writer)%3A). Your training loop should save the model with the lowest validation loss score. \n",
    "\n",
    "NOTE: if you experience freezing or kernel dying, try reducing your batch size and defining a model with less parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b563aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define model hyperparameters and use train_regression() to train \n",
    "#       your CNN regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95edd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot the training and validation loss histories of your custom model separately\n",
    "#       Don't forget proper axis labels and titles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad58b1c2",
   "metadata": {},
   "source": [
    "### Outline the results of your custom regression training.\n",
    "\n",
    "If you are not getting low validation accuracy you may need to collect more data, revise your model architecture, or adjust hyperparameters. Explain your process of improving the model's performance below.\n",
    "\n",
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3d3146",
   "metadata": {},
   "source": [
    "## Part 2.4 Custom Regression Live Inference\n",
    "\n",
    "We will now use the custom trained model to do live classification through the webcam. \n",
    "\n",
    "TODO: Complete the function **live_regression()** in **utils/live_inference.py**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad52c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "live_regression(model_save_path, model, device, regression_class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524b7d99",
   "metadata": {},
   "source": [
    "### Discuss the performance of the live inference. Is the model able to do inference fast enough for the feed to be real time? Is the regression accurate?\n",
    "\n",
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c56041f",
   "metadata": {},
   "source": [
    "### Insert a screenshot of your custom model regression below.\n",
    "\n",
    "TODO: insert custom model regression screenshot here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf1749a",
   "metadata": {},
   "source": [
    "## Part 2.5 Custom Regression Live Inference\n",
    "\n",
    "In this part we repeat parts 1.2 - 1.4 with a [pretrained ResNet18](https://pytorch.org/hub/pytorch_vision_resnet/). We have defined the pretrained PyTorch implementation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1105f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "resnet18.fc = torch.nn.Linear(512, 2 * len(regression_class_names))\n",
    "resnet18.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88e7559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use train_regression() to fine tune ResNet18 for your dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8276b532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot the training and validation loss histories of ResNet18 separately\n",
    "#       Don't forget proper axis labels and titles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c620d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: execute live regression with the ResNet18 regression model using live_regression()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3675f8",
   "metadata": {},
   "source": [
    "### Discuss the difference in performance between your custom model and the pretrained ResNet18 in the regression task. Were you able to fine tune the regression to your dataset? Which model's training and validation losses converged quicker? Why? Is there a considerable difference in inference speed between the two models?\n",
    "\n",
    "TODO: Your answer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8e4b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
